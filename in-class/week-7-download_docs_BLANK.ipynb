{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"week-7-download_docs_BLANK.ipynb","provenance":[{"file_id":"1J1lhUQakLF4NmWxBeEGiprUMSv1j7cpk","timestamp":1628019785208}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ja871rAui_Da"},"source":["# Scraping Files from Websites "]},{"cell_type":"markdown","metadata":{"id":"KwHrS-KJi_Dg"},"source":["### You need to create a data set that tracks how many companies the <a href=\"https://www.sec.gov/litigation/suspensions.shtml\">SEC suspended</a> between 2019 and 1999. You find the data at:\n","\n","```https://www.sec.gov/litigation/suspensions.shtml```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-_OAOaqLi_Dh"},"source":["### We want to write a scraper that aggregates:\n","\n","* Date of suspension\n","* Company name\n","* Order\n","* Release (the PDFs in the XX-YYYYY format)"]},{"cell_type":"markdown","metadata":{"id":"ECK4Q7IOi_Di"},"source":["# The Challenge?"]},{"cell_type":"markdown","metadata":{"id":"oQj34GvYi_Di"},"source":["### Details are actually in PDFs!"]},{"cell_type":"markdown","metadata":{"id":"VfkXDlQvi_Di"},"source":["# Demo downloading files from websites "]},{"cell_type":"markdown","metadata":{"id":"qyvf5HLGi_Dj"},"source":["There are ```txt``` and ```pdf``` files on:\n","\n","```https://sandeepmj.github.io/scrape-example-page/pages.html```\n","\n","Do the following:\n","\n","1. Download all ```txt``` files.\n","2. Download all ```pdf``` files.\n","3. Download all files as one."]},{"cell_type":"code","metadata":{"id":"W1jQ2nQei_Dj"},"source":["# import libraries\n","from bs4 import BeautifulSoup  ## scrape info from web pages\n","import requests ## get web pages from server\n","import time # time is required. we will use its sleep function\n","from random import randrange # generate random numbers\n","\n","# from google.colab import files ## code for downloading in google colab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cV7Mwt-Ai_Dk"},"source":["# url to scrape\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cyHHqpmYi_Dk"},"source":["## Turn page into soup"]},{"cell_type":"code","metadata":{"id":"dIkCJBH8i_Dk"},"source":["## get url and print but hard to read. will do prettify next\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z42CN1eKi_Dk"},"source":["## Find all txt files"]},{"cell_type":"code","metadata":{"id":"l5GhvRuji_Dl"},"source":["## save in list called txt_holder\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T8sCo7syi_Dl"},"source":["## Find all the ```a``` tags "]},{"cell_type":"code","metadata":{"id":"1BBjQWqsi_Dl"},"source":["## for loop"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UPgFpi0ui_Dl"},"source":["## look at the links\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h3Sv-zUhi_Dm"},"source":["## What is missing from the URLs?"]},{"cell_type":"code","metadata":{"id":"BR4K5BkGi_Dm"},"source":["## base url\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g8sgMa05i_Dm"},"source":["## Create a list of the full URLs\n","\n","Without all the ```html```"]},{"cell_type":"code","metadata":{"id":"VOJEvd2ki_Dm"},"source":["## lc\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CCqmE0y6i_Dm"},"source":["## Download all the ```txt``` documents"]},{"cell_type":"code","metadata":{"id":"zUM7ToNEi_Dn"},"source":["import wget # can put down documents, files from websites"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_aUuV5ci_Dn"},"source":["## download with timer\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zt6eKURbi_Dn"},"source":["# Find all ```pdf``` files"]},{"cell_type":"code","metadata":{"id":"T0aipPxyi_Dn"},"source":["## grab pdfs\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XUEScUwei_Dn"},"source":["## Find all the ```a``` tags "]},{"cell_type":"code","metadata":{"id":"DohlMXf2i_Do"},"source":["## for loop store in all_pdf_links_fl\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AfSN4n4Ki_Do"},"source":["## Find all the ```a``` tags \n","\n","Without all the ```html```"]},{"cell_type":"code","metadata":{"id":"hp00Mel0i_Do"},"source":["## lc store in all_pdf_links\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C8QfQI1Qi_Do"},"source":["## Download all the ```pdf``` documents"]},{"cell_type":"code","metadata":{"id":"W7-meNFri_Do"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yLOjF-XKi_Do"},"source":["# Find all the files and download at one go"]},{"cell_type":"code","metadata":{"id":"XmMZ8b0Di_Dp"},"source":["## find all files in our soup\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XIAFCQvci_Dp"},"source":["## Stop...we can't throw such a wide net!"]},{"cell_type":"markdown","metadata":{"id":"Toth3b6ui_Dp"},"source":["# Target the class ```downloadable```"]},{"cell_type":"code","metadata":{"id":"-6mKi4RWi_Dp"},"source":["## find all files in our soup\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"grnOHd9di_Dp"},"source":["## type?\n","type(docs_holder)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TGQeldzsi_Dp"},"source":["### We run into problems because we have a list of lists\n","\n","#### Quick detour to flatten list lesson"]},{"cell_type":"code","metadata":{"id":"ghmEL1-1i_Dq"},"source":["## because docs_holder has p tags, newlines, etc. we need to focus it\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YkYtIzr_i_Dq"},"source":["## itertools"]},{"cell_type":"code","metadata":{"id":"F729Ln8ci_Dq"},"source":["## let's use itertools to flatten the list\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKg_eOsOi_Dq"},"source":["## let's blend BeautifulSoup and itertools\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pA22k16Wi_Dq"},"source":["## For Loop"]},{"cell_type":"code","metadata":{"id":"UUe6Ikfri_Dq"},"source":["## Flatten via for loop\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dZH5X9IBi_Dr"},"source":["## List Comprehension"]},{"cell_type":"code","metadata":{"id":"qXBeF0ubi_Dr"},"source":["# step 1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oToaTbmKi_Dr"},"source":["# step 2\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9wjrnhrui_Dr"},"source":["## Download all documents"]},{"cell_type":"code","metadata":{"id":"GXpDuRyvi_Dr"},"source":["## careful to put in a list name we just processed (via lc, fl, itertools)\n"],"execution_count":null,"outputs":[]}]}